\chapter{Conclusion}\label{chap:conclusion}
In this thesis, we have explored the domain of metadata extraction from scientific publications, with a particular focus on historic articles in the field of Geography written in German. Through extensive research and analysis, we explored various novel approaches, existing literature, and software solutions to gain a comprehensive understanding of how researchers have addressed this challenging problem.\\
The central objective of our work was to develop a robust and unified system capable of accurately extracting metadata from document headers and references, regardless of the language in which they are written, be it English or German. To achieve this goal, we collected and annotated scientific articles, culminating in the creation of two essential datasets.\\
The first dataset, geared towards document segmentation, comprises 1,365 self-annotated pages sourced from historical literature in Geography, supplemented with a reviewed sample of 1,500 pages from the DocBank dataset. The second dataset was created for reference segmentation and parsing, encompassing 5,073 self-annotated reference strings alongside an additional 12,496 reference strings procured from the EXCITE project.\\
To accomplish our task, we propose our unified system BiBEx, a cascading system that utilizes three fine-tuned transformer models to extract both header metadata and reference metadata from scientific articles. This approach enables us to obtain accurate and reliable results, showcasing the system's versatility and effectiveness across various different articles.\\
Furthermore, we designed and implemented two applications, BiBEx-UI and BiBEx-Model. These applications facilitate fast and user-friendly metadata extraction for a large number of documents, streamlining the process and making it accessible to a broader audience.\\
We evaluated multiple fine-tuned transformer models, in conjunction with baseline models, to assess their individual performances. Additionally, we conducted an overall evaluation of the system's ability to extract authors and references, demonstrating the capabilities of BiBEx compared to commonly used tools like GROBID, with equal or better performance observed in most metrics.\\
While our work presents a novel approach with good results in metadata extraction from scientific publications, we acknowledge that there are certain limitations, like the overall quantity of samples in our datasets. \\
In conclusion, our research contributes to the field of metadata extraction in scientific publications by providing a robust and unified system, BiBEx, capable of efficiently handling document headers and references in multiple languages. We hope that the insights gained from this thesis will inspire future research and development in this domain.

\section{Future Work}
For our Future Work, we propose several quality-of-life improvements that will enhance the overall user experience of BiBEx. Firstly, we plan small enhancements such as the implementation of an alive check for the BiBEx-Model. Additionally, we aim to enable users to upload multiple PDFs simultaneously in the BiBEx-UI, simplifying the process for batch metadata extraction.\\
To address limitations we encountered with the extraction of authors, we intend to replace the currently employed heuristics with a more sophisticated ML model. This change could enable a more accurate and reliable extraction of author names, especially in cases where complex name constellations are present.\\
Another future step is exploring the possibility of annotating the document segmentation dataset using an IOB-tag approach. This approach will allow the document segmentation model to segment references at an earlier stage of our model cascade, streamlining the entire process and enabling the Reference Parser model to focus solely on parsing the segmented references.\\
Expanding our model collection is another key aspect of our future work. We plan to explore the effectiveness of additional models such as distilBERT~\cite{sanh2019distilbert}, a BERT-like transformer that is faster and lighter, and sciBERT~\cite{beltagy2019scibert}, specifically trained on a large corpus of scientific publications. This exploration will provide insights into the potential performance increases that different models may offer.\\
Hyperparameter tuning is an important aspect of ML model development, and we plan to conduct more extensive hyperparameter tuning for our models.\\
Finally, we recognize the importance of increasing the quantity of both our training and evaluation sets. By expanding the datasets, we can provide a more definitive validation of our results, increasing the confidence in our proposed application, BiBEx.